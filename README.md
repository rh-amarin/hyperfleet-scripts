# HyperFleet Scripts

CLI utilities for managing HyperFleet clusters, node pools, databases, and Kubernetes resources.

## Quick Start

```bash
hf.config.sh bootstrap my-env    # Interactive setup: context, API, port-forwards, DB
hf.config.sh doctor              # Check which scripts are ready to use
```

## Config System

All scripts use a **file-based configuration** system with environment variable overrides:

- **Config location**: `~/.config/hf/` (one file per setting)
- **Precedence**: Environment variables > config files > defaults
- **Shared state**: Settings persist across script invocations
- **Property registry**: All config keys are declared once in `HF_CONFIG_REGISTRY` in `hf.lib.sh`
- **Dependency tracking**: Each script declares its required config via `hf_require_config`

### Managed via `hf.config.sh`

```bash
hf.config.sh                      # Show help, environments, and active config
hf.config.sh show                 # Show current configuration
hf.config.sh show my-env          # Show config with environment overrides highlighted
hf.config.sh set api-url <url>    # Set API URL
hf.config.sh clear token          # Clear auth token
hf.config.sh clear all            # Reset everything
hf.config.sh doctor               # Check per-script readiness
hf.config.sh bootstrap [env]      # Interactive environment setup
hf.config.sh env list             # List environments
hf.config.sh env activate <name>  # Activate an environment
```

Settings are grouped into sections in the registry:

**hyperfleet**: `api-url`, `api-version`, `token`, `context`, `namespace`, `gcp-project`, `cluster-id`, `cluster-name`, `nodepool-id`

**maestro**: `maestro-consumer`, `maestro-http-endpoint`, `maestro-grpc-endpoint`, `maestro-namespace`

**portforward**: `pf-api-port`, `pf-pg-port`, `pf-maestro-http-port`, `pf-maestro-http-remote-port`, `pf-maestro-grpc-port`

**database**: `db-host`, `db-port`, `db-name`, `db-user`, `db-password`

### Adding a new config property

1. Add one line to `HF_CONFIG_REGISTRY` in `hf.lib.sh`
2. Add a `HF_*_FILE` variable and `_hf_load` call in the same file
3. Add a setter function if scripts need to set it programmatically
4. Scripts that need it add the key to their `hf_require_config` call

No other files need to change -- `hf.config.sh`, environments, and doctor all derive from the registry.

## Scripts Overview

### Cluster Management

| Script | Description |
|--------|-------------|
| `hf.cluster.create.sh` | Create a new cluster via API |
| `hf.cluster.delete.sh` | Delete cluster by ID |
| `hf.cluster.get.sh` | Get cluster details by ID |
| `hf.cluster.search.sh` | Search clusters by name and set as current |
| `hf.cluster.list.sh` | List all clusters |
| `hf.cluster.table.sh` | Display clusters in table format |
| `hf.cluster.id.sh` | Show current cluster ID |
| `hf.cluster.conditions.sh` | Show cluster conditions (`-w` for watch) |
| `hf.cluster.statuses.sh` | Show cluster adapter statuses (`-w` for watch) |

### NodePool Management

| Script | Description |
|--------|-------------|
| `hf.nodepool.create.sh` | Create a node pool under the current cluster |
| `hf.nodepool.delete.sh` | Delete a node pool |
| `hf.nodepool.get.sh` | Get node pool details |
| `hf.nodepool.list.sh` | List node pools for the current cluster |
| `hf.nodepool.conditions.sh` | Show node pool conditions (`-w` for watch) |
| `hf.nodepool.statuses.sh` | Show node pool adapter statuses (`-w` for watch) |

### Database Operations

| Script | Description |
|--------|-------------|
| `hf.db.config.sh` | Interactive database configuration |
| `hf.db.query.sh` | Execute SQL queries or files |
| `hf.db.delete.sh` | Delete database records |
| `hf.db.statuses.sh` | Query cluster status table |
| `hf.db.statuses.delete.sh` | Delete status records |

### Kubernetes Helpers

| Script | Description |
|--------|-------------|
| `hf.kube.context.sh` | Select and save kubectl context/namespace |
| `hf.kube.curl.sh` | Run curl from inside a cluster pod (see below) |
| `hf.kube.debug.pod.sh` | Create debug pod cloned from a deployment (see below) |
| `hf.kube.port.forward.sh` | Port forward to services/pods |
| `hf.logs.sh` | Tail pod logs with context |

#### `hf.kube.curl.sh`

Runs curl from inside a pod in the current Kubernetes cluster, useful for reaching cluster-internal services. The pod (`hf-kcurl`) is reused across invocations and auto-terminates after 5 minutes via `sleep 300`, so the first call pays the pod startup cost but subsequent calls are fast. Only curl output is written to stdout, making the script safe to use in pipelines and other scripts.

```bash
# Simple GET
hf.kube.curl.sh http://my-service.ns.svc:8080/health

# POST with inline data
hf.kube.curl.sh -X POST -H "Content-Type: application/json" -d '{"key":"val"}' http://my-service.ns.svc:8080/api

# POST with file body
hf.kube.curl.sh -X POST -H "Content-Type: application/json" -f payload.json http://my-service.ns.svc:8080/api

# Save response to file
hf.kube.curl.sh -o response.json http://my-service.ns.svc:8080/api

# Use in a pipeline
hf.kube.curl.sh http://my-service.ns.svc:8080/api | jq '.items[]'
```

#### `hf.kube.debug.pod.sh`

Creates a debug pod by cloning the pod template from an existing deployment. The debug pod runs with the same image, environment variables, volumes, and service account as the original deployment, but replaces the entrypoint with `sleep infinity` and removes all health probes. This lets you exec into a shell with the exact same runtime context as the target workload â€” useful for debugging configuration, network connectivity, or permissions issues.

The deployment is matched by partial name, so you don't need to type the full name.

```bash
# Clone a deployment's pod template into a debug pod and exec into it
hf.kube.debug.pod.sh my-app

# Specify a namespace
hf.kube.debug.pod.sh my-app staging

# Clean up when done
kubectl delete pod my-app-debug-<timestamp> -n default
```

### Maestro

Maestro scripts require `maestro-cli` to be compiled and available on your `PATH` from [openshift-hyperfleet/maestro-cli](https://github.com/openshift-hyperfleet/maestro-cli).

| Script | Description |
|--------|-------------|
| `hf.maestro.list.sh` | List maestro resources |
| `hf.maestro.get.sh` | Get a maestro resource by name (interactive selection if no name given) |
| `hf.maestro.delete.sh` | Delete a maestro resource by name (interactive selection if no name given) |
| `hf.maestro.bundles.sh` | List maestro resource bundles |

### Other Utilities

| Script | Description |
|--------|-------------|
| `hf.adapter.status.sh` | Post adapter status for current cluster |
| `hf.pubsub.publish.sh` | Publish messages to Pub/Sub |
| `hf.lib.sh` | Shared library (config registry, API helpers, logging, Kubernetes wrappers) |

## Common Patterns

**Bootstrap a new environment**:
```bash
hf.config.sh bootstrap dev
```

**Check what's ready**:
```bash
hf.config.sh doctor
```

**Search and set current cluster**:
```bash
hf.cluster.search.sh my-cluster-name
```

**Query cluster details** (uses saved cluster-id):
```bash
hf.cluster.get.sh
```

**Create and manage node pools**:
```bash
hf.nodepool.create.sh my-pool 3 m5.2xlarge
hf.nodepool.list.sh
hf.nodepool.conditions.sh -w
```

**Switch environments**:
```bash
hf.config.sh env list
hf.config.sh env activate staging
```

**Configure kubectl context**:
```bash
hf.kube.context.sh select
```

**Run database query**:
```bash
hf.db.query.sh "SELECT * FROM clusters LIMIT 10"
hf.db.query.sh -f schema.sql
```

## Architecture

- **hf.lib.sh**: Core library providing config registry, config loading, API helpers, logging, and Kubernetes wrappers
- **Config registry**: `HF_CONFIG_REGISTRY` in `hf.lib.sh` is the single source of truth for all config properties (section, key, default, sensitivity)
- **Dependency declarations**: Each script declares `hf_require_config <keys>` -- used at runtime for validation and by `doctor` for readiness scanning
- **File-based state**: Each config value stored separately in `~/.config/hf/` for easy inspection and editing
- **Environment profiles**: Named environments stored as `<env>.<property>` files in the config directory
- **Environment override**: Set `HF_API_URL`, `HF_TOKEN`, etc. to override file config
- **Consistent interface**: All scripts source `hf.lib.sh` for unified behavior and error handling
